{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2hkgQr7v/Ueon+ydBa6U8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeking-illinois/illinois-splunk-cloud-custom-apps/blob/AAA_uofi_urb_splunkmgmt_APP/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg6d9CqXZYdU",
        "outputId": "6be07fa4-62cd-45af-d351-ad49935e1f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "  Downloading pyspark-2.4.4.tar.gz (215.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7 MB 66 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 21.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130392 sha256=9a5cde871d9fc34c14358f49db3e6936552a63d204b86b98179a72c086dc2566\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/48/19/c3b6b66e4575c164407a83bc065179904ddc33c9d6500846f0\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.6.3\n",
            "  Downloading spark_nlp-2.6.3-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 16.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SP-Y1aIZ6d1",
        "outputId": "01ad6b67-99c2-4c55-e47f-43c7f1d693e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  2.6.3\n",
            "Apache Spark version:  2.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.train\"\n",
        "if not Path(download_path).is_file():\n",
        "  print(\"File Not found will downloading it!\")\n",
        "  url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
        "  urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        "  print(\"File already present.\")"
      ],
      "metadata": {
        "id": "hEFHO2pggPDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.testa\"\n",
        "if not Path(download_path).is_file():\n",
        "  print(\"File Not found will downloading it!\")\n",
        "  url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
        "  urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        "  print(\"File already present.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDW5Mypsa-Or",
        "outputId": "2e09dbaa-ccee-406e-b268-9244efe67fb3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Not found will downloading it!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.training import CoNLL\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui22xoCUcAQk",
        "outputId": "76536d76-cba4-482d-dda0-0be6bf0aed58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
            "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
            "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
            "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
            "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
            "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
            "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = BertEmbeddings.pretrained('bert_base_cased', 'en').setInputCols([\"sentence\",'token']).setOutputCol(\"bert\").setCaseSensitive(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1uvtdGicMQ7",
        "outputId": "04cdd874-8aa6-4c8a-8a90-e0029ca2ae9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nerTagger = NerDLApproach().setInputCols([\"sentence\", \"token\", \"bert\"]).setLabelColumn(\"label\").setOutputCol(\"ner\").setMaxEpochs(1).setRandomSeed(0).setVerbose(1).setValidationSplit(0.2).setEvaluationLogExtended(True).setEnableOutputLogs(True).setIncludeConfidence(True).setTestDataset(\"test_withEmbeds.parquet\")"
      ],
      "metadata": {
        "id": "aps9ed4ycONN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "test_data = bert.transform(test_data)\n",
        "test_data.write.parquet(\"test_withEmbeds.parquet\")"
      ],
      "metadata": {
        "id": "Z3UJEOE-dxX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ner_pipeline = Pipeline(stages = [bert, nerTagger])\n",
        "ner_model = ner_pipeline.fit(training_data)"
      ],
      "metadata": {
        "id": "Ld1krDZXenXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ner_model.trainsform(test_data)\n",
        "predictions.show()"
      ],
      "metadata": {
        "id": "8Uc2yZglew94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
      ],
      "metadata": {
        "id": "6fKhIC6Ue5Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.printSchema()"
      ],
      "metadata": {
        "id": "qx1QXci5fQDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")).select(F.expr(\"cols['0']\").alias(\"token\"),F.expr(\"cols['1']\").alias(\"ground_truth\"),F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "metadata": {
        "id": "pwHkVtL3fWCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}